@article{antonazzi2024privacyweakloss,
  abbr={arXiv},
  title={Privacy-Oriented Object Detection in Curious Cloud Robotics via Proposal Selection},
  author={Antonazzi, Michele and Alberti, Matteox    and Bassot, Alex and Luperto, Matteo and Basilico, Nicola},
  year={2024},
  bibtex_show={False},
  website={https://aislab.di.unimi.it/research/privacyweakloss/},
  selected={true},
  note={(Under Review)},
  abstract={Cloud robotics enables low-powered robots to perform high-demand inference tasks by offloading them to the cloud, but raises privacy concerns when transmitting sensitive images. While end-to-end encryption secures data in transit, it does not protect against potential misuse by third-party curious services as data need to be decrypted for inference. This paper addresses these privacy issues in cloud-based object detection (OD) tasks. Our approach involves co-training an encoder-decoder architecture to retain only task-specific features while obfuscating sensitive information, leveraging a novel mechanism of weak loss with proposal selection for privacy-preservation. We evaluated the trade-off between detection accuracy and privacy preservation through an extensive experimental analysis on public datasets.}
}
@inproceedings{antonazzi2024r2snet,
      abbr={IROS},
      title={R2SNet: Scalable Domain Adaptation for Object Detection in Cloud-Based Robots Ecosystems via Proposal Refinement},
      author={Michele Antonazzi and Matteo Luperto and N. Alberto Borghese and Nicola Basilico},
      selected={true},
      pdf={https://doi.org/10.48550/arXiv.2403.11567},
      website={https://aislab.di.unimi.it/research/r2snet},
      year={2024},
      organization={IEEE},
      booktitle={2024 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
      bibtex_show={true},
        abstract={We introduce a novel approach for scalable domain adaptation in cloud robotics scenarios where robots rely on third-party AI inference services powered by large pre-trained deep neural networks. Our method is based on a downstream proposal-refinement stage running locally on the robots, exploiting a new lightweight DNN architecture, R2SNet. This architecture aims to mitigate performance degradation from domain shifts by adapting the object detection process to the target environment, focusing on relabeling, rescoring, and suppression of bounding-box proposals. Our method allows for local execution on robots, addressing the scalability challenges of domain adaptation without incurring significant computational costs. Real-world results on mobile service robots performing door detection show the effectiveness of the proposed method in achieving scalable domain adaptation.},
      video={r2snet_video_extended.mp4},
      poster={IROS-2024-R2SNet-poster.pdf}
}

@inproceedings{tellaroli2024frontierbased,
      title={Frontier-Based Exploration for Multi-Robot Rendezvous in Communication-Restricted Unknown Environments},
      author={Mauro Tellaroli and Matteo Luperto and Michele Antonazzi and Nicola Basilico},
      booktitle={2024 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
      year={2024},
      bibtex_show={true},
      organization={IEEE},
      video={frontierbased_exploration.mp4},
      abbr={IROS},
      website={https://aislab.di.unimi.it/research/fberendezvous/},
      pdf={https://doi.org/10.48550/arXiv.2403.11617},
      poster={2024IROS_FBRrendezvous_poster.pdf},
      abstract={Multi-robot rendezvous and exploration are fundamental challenges in the domain of mobile robotic systems. This paper addresses multi-robot rendezvous within an initially unknown environment where communication is only possible after the rendezvous. Traditionally, exploration has been focused on rapidly mapping the environment, often leading to suboptimal rendezvous performance in later stages. We adapt a standard frontier-based exploration technique to integrate exploration and rendezvous into a unified strategy, with a mechanism that allows robots to re-visit previously explored regions thus enhancing rendezvous opportunities. We validate our approach in 3D realistic simulations using ROS, showcasing its effectiveness in achieving faster rendezvous times compared to exploration strategies.},
}

@article{antonazzi2024development,
  abbr={arXiv},
  title={Development and Adaptation of Robotic Vision in the Real-World: the Challenge of Door Detection},
  author={Antonazzi, Michele and Luperto, Matteo and Borghese, N. Alberto and Basilico, Nicola},
  year={2024},
  bibtex_show={true},
  pdf={https://doi.org/10.48550/arXiv.2401.17996},
  website={https://aislab.di.unimi.it/research/doordetection/},
  selected={true},
  note={(Under Review)},
  abstract={Mobile service robots are increasingly prevalent in human-centric, real-world domains, operating autonomously in unconstrained indoor environments. In such a context, robotic vision plays a central role in enabling service robots to perceive high-level environmental features from visual observations. Despite the data-driven approaches based on deep learning push the boundaries of vision systems, applying these techniques to real-world robotic scenarios presents unique methodological challenges. Traditional models fail to represent the challenging perception constraints typical of service robots and must be adapted for the specific environment where robots finally operate. We propose a method leveraging photorealistic simulations that balances data quality and acquisition costs for synthesizing visual datasets from the robot perspective used to train deep architectures. Then, we show the benefits in qualifying a general detector for the target domain in which the robot is deployed, showing also the trade-off between the effort for obtaining new examples from such a setting and the performance gain. In our extensive experimental campaign, we focus on the door detection task (namely recognizing the presence and the traversability of doorways) that, in dynamic settings, is useful to infer the topology of the map. Our findings are validated in a real-world robot deployment, comparing prominent deep-learning models and demonstrating the effectiveness of our approach in practical settings.}
}
@inproceedings{antonazzi2023enhancing,
  abbr={ECMR},
  title={Enhancing Door-Status Detection for Autonomous Mobile Robots during Environment-Specific Operational Use},
  author={Antonazzi, Michele and Luperto, Matteo and Basilico, Nicola and Borghese, N. Alberto},
  booktitle={2023 European Conference on Mobile Robots (ECMR)},
  year={2023},
  organization={IEEE},
  selected={true},
  bibtex_show={true},
  video={ecmr_door_detection.gif},
  pdf={https://doi.org/10.1109/ECMR59166.2023.10256289},
  abstract={Door-status detection, namely recognising the presence of a door and its status (open or closed), can induce a remarkable impact on a mobile robot's navigation performance, especially for dynamic settings where doors can enable or disable passages, changing the topology of the map. In this work, we address the problem of building a door-status detector module for a mobile robot operating in the same environment for a long time, thus observing the same set of doors from different points of view. First, we show how to improve the mainstream approach based on object detection by considering the constrained perception setup typical of a mobile robot. Hence, we devise a method to build a dataset of images taken from a robot's perspective and we exploit it to obtain a door-status detector based on deep learning. We then leverage the typical working conditions of a robot to qualify the model for boosting its performance in the working environment via fine-tuning with additional data. Our experimental analysis shows the effectiveness of this method with results obtained both in simulation and in the real-world, that also highlights a trade-off between the costs and benefits of the fine-tuning approach.}
}

@article{luperto2020robot,
  title={Robot exploration of indoor environments using incomplete and inaccurate prior knowledge},
  author={Luperto, Matteo and Antonazzi, Michele and Amigoni, Francesco and Borghese, N. Alberto},
  journal={Robotics and Autonomous Systems},
  volume={133},
  pages={103622},
  year={2020},
  publisher={Elsevier},
  selected={true},
  abbr = {AURO},
  bibtex_show={true},
  pdf={https://doi.org/10.1016/j.robot.2020.103622},
  doi={10.1016/j.robot.2020.103622},
  abstract={Exploration is a task in which autonomous mobile robots incrementally discover features of interest in initially unknown environments. We consider the problem of exploration for map building, in which a robot explores an indoor environment in order to build a metric map. Most of the current exploration strategies used to select the next best locations to visit ignore prior knowledge about the environments to explore that, in some practical cases, could be available. In this paper, we present an exploration strategy that evaluates the amount of new areas that can be perceived from a location according to a priori knowledge about the structure of the indoor environment being explored, like the floor plan or the contour of external walls. Although this knowledge can be incomplete and inaccurate (e.g., a floor plan typically does not represent furniture and objects and consequently may not fully mirror the structure of the real environment), we experimentally show, both in simulation and with real robots, that employing prior knowledge improves the exploration performance in a wide range of settings.}
}
